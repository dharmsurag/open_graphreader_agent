{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e48d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet neo4j langchain-community langchain-core langchain-openai langchain-text-splitters tiktoken wikipedia langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json \n",
    "import neo4j\n",
    "from typing import List, Type, Optional\n",
    "from pydantic import Field, BaseModel, ValidationError\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44170567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set up GROQ API Key ---\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    print(\"GROQ_API_KEY not found in environment variables. Please set it in the .env file.\")\n",
    "    # os.environ[\"GROQ_API_KEY\"] = \"replace_with_your_groq_api_key\"  # Uncomment and set your key if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede97367",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7031cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Pydantic model\n",
    "class AtomicFact(BaseModel):\n",
    "    key_elements: List[str]\n",
    "    atomic_fact: str\n",
    "\n",
    "\n",
    "class ChunkEnrichment(BaseModel):\n",
    "    atomic_facts: List[AtomicFact]\n",
    "\n",
    "\n",
    "#Output parser\n",
    "parser = PydanticOutputParser(pydantic_object=ChunkEnrichment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e757ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define prompt template with a placeholder for the input\n",
    "enrichment_prompt = (\n",
    "    \"You are an intelligent assistant tasked with meticulously extracting structured information consisting:\\n\\n\"\n",
    "    \"1. Key Elements: The essential nouns (e.g., characters, times, events, places, numbers) or verbs (actions), or adjectives (states, feelings) pivotal to the text's narrative.\\n\"\n",
    "    \"2. Atomic Facts: The smallest, indivisible facts, presented as concise sentences. Each Fact must:\\n\"\n",
    "    \"   - Be stand alone, with no ambiguity or missing context.\\n\"\n",
    "    \"   - Include all necessary details (e.g., full names, dates, numbers).\\n\"\n",
    "    \"   - Clarify any ambiguous terms.\\n\"\n",
    "    \"   - Not depend on any other fact for meaning.\\n\"\n",
    "    \"   - Avoid hallucination or guessing; only use information present in the text.\\n\"\n",
    "    \"Use the format: \\n{format_instructions}\\n for response from the following text:\\n{placeholder}\"\n",
    ")\n",
    "\n",
    "enrichment_temp = PromptTemplate(\n",
    "    template=enrichment_prompt,\n",
    "    input_variables=[\"placeholder\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "rendered_prompt = enrichment_temp.format(placeholder=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a30df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_client(input,prompt=None):\n",
    "    \"\"\"Invoke the LLM with the given input.\"\"\"\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            prompt,\n",
    "        ),\n",
    "        (\"human\", input),\n",
    "    ]\n",
    "    return llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ceb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_response(response: str):\n",
    "    \"\"\"\n",
    "    Extracts the first JSON code block from a string and parses it.\n",
    "    Returns the parsed Python object, or None if not found/invalid.\n",
    "    \"\"\"\n",
    "    # Regex to find a JSON code block (```json ... ```)\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", response, re.DOTALL)\n",
    "    if not match:\n",
    "        # Fallback: try to find any {...} block\n",
    "        match = re.search(r\"(\\{.*\\})\", response, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e)\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ef38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facts_and_entities(content):\n",
    "    op = llm_client(content, rendered_prompt)\n",
    "    extracted_json = extract_json_from_response(op)\n",
    "    return extracted_json['atomic_facts'] if extracted_json and 'atomic_facts' in extracted_json else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j connection\n",
    "driver = neo4j.GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"neo4j1999\"))\n",
    "NEO4J_DATABASE = \"graphreader1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_knowledge_graph(patient_data):\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        for patient_id, domains in patient_data.items():\n",
    "            # Create Patient node\n",
    "            session.run(\"MERGE (p:Patient {id: $id})\", id=patient_id)\n",
    "\n",
    "\n",
    "            # Process each domain\n",
    "            for domain_name, content in domains.items():\n",
    "                session.run(\n",
    "                    \"MATCH (p:Patient {id: $patient_id}) \"\n",
    "                    \"MERGE (d:Domain {name: $name, content: $content}) \"\n",
    "                    \"MERGE (p)-[:HAS_DOMAIN]->(d)\",\n",
    "                    patient_id=patient_id, name=domain_name, content=content\n",
    "                )\n",
    "                # Extract and store facts and entities\n",
    "                facts = extract_facts_and_entities(content)\n",
    "                for fact_data in facts:\n",
    "                    atomic_fact = fact_data[\"atomic_fact\"]\n",
    "                    key_elements = fact_data[\"key_elements\"]\n",
    "                    fact_result = session.run(\n",
    "                        \"MATCH (d:Domain {name: $name, content: $content}) \"\n",
    "                        \"MERGE (f:AtomicFact {fact: $fact}) \"\n",
    "                        \"MERGE (d)-[:CONTAINS_FACT]->(f) \"\n",
    "                        \"RETURN id(f) AS fact_id\",\n",
    "                        name=domain_name, content=content, fact=atomic_fact\n",
    "                    )\n",
    "                    fact_id = fact_result.single()[\"fact_id\"]\n",
    "                    for entity in key_elements:\n",
    "                        session.run(\n",
    "                            \"MATCH (f:AtomicFact) WHERE id(f) = $fact_id \"\n",
    "                            \"MERGE (e:KeyEntity {name: $name}) \"\n",
    "                            \"MERGE (f)-[:HAS_ENTITY]->(e)\",\n",
    "                            fact_id=fact_id, name=entity\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46929178",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"diverse_patient_data.json\", \"r\") as f:\n",
    "        patient_data = json.load(f)\n",
    "ingest_knowledge_graph(patient_data)\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
